eval:
  batch_size: 200

model:
  embed_dim: 600
  dropout_rate: 0.5
  encoder_dims: [200]
  decoder_dims: [200]
  activation: tanh

train:
  anneal_max: 0.2
  anneal_total_step: 2000000
  batch_size: 500
  epochs: 500
  learner: adam
  learning_rate: 0.001
  weight_decay: 1e-5
  early_stop_patience: 100
