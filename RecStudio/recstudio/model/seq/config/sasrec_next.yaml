data:
  split_mode: user
  split_ratio: [1.0]
  max_seq_len: 10

eval:
  batch_size: 1024
  predict_topk: 100
  test_metrics: [recall, precision, map, ndcg, mrr, hit]
  val_metrics: [mrr, recall, precision, ndcg]
  cutoff: [100, 200, 300]
  topk: 300

model:
  # transformer
  embed_dim: 128
  activation: 'gelu'
  dropout_rate: 0.5
  hidden_size: 256
  head_num: 2
  layer_norm_eps: 1e-12
  layer_num: 1
  loss_func: softmax
  reverse_pos: True

train:
  batch_size: 1024
  early_stop_patience: 10
  epochs: 300
  init_method: default
  init_range: 0.02
  negative_count: ~
  scheduler: onplateau
  pretrained_embed_file: ~
  learning_rate: 0.001
  # pretrained_embed_file: /root/autodl-tmp/huangxu/Amazon-KDDCUP-23/co-occurrence_graph/graph_emb_128.pkl
  # scheduler: onplateau
  # weight_decay: 1e-6
