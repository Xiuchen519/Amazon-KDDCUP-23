{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part0: Necessary Common Functions\n",
    "\n",
    "Those functions should be ran before each part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as ssp\n",
    "from functools import lru_cache\n",
    "from tqdm import tqdm\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache loading of data for multiple calls\n",
    "train_data_dir = '../raw_data/'\n",
    "test_data_dir = '../raw_data/'\n",
    "task = 'task1'\n",
    "PREDS_PER_SESSION = 100\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def read_product_data():\n",
    "    print(os.getcwd())\n",
    "    print(os.path.join(train_data_dir, 'products_train.csv'))\n",
    "    return pd.read_csv(os.path.join(train_data_dir, 'products_train.csv'))\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def read_train_data():\n",
    "    return pd.read_csv(os.path.join(train_data_dir, 'sessions_train.csv'))\n",
    "\n",
    "@lru_cache(maxsize=3)\n",
    "def read_test_data(task):\n",
    "    return pd.read_csv(os.path.join(test_data_dir, f'sessions_test_{task}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_id(id: str, id_dict: dict) -> int:\n",
    "    return id_dict[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_sessions(df: pd.DataFrame, id_dict: dict, test=False, list_item=False) -> list:\n",
    "    if 'next_item' in df and not test:\n",
    "        if list_item:\n",
    "            all_item = df['prev_items']\n",
    "        else:\n",
    "            all_item = df.apply(lambda x: eval((x['prev_items'][:-1]+f\" '{x['next_item']}']\").replace(\" \", \",\")), axis=1)\n",
    "    else:\n",
    "        if list_item:\n",
    "            all_item = df['prev_items']\n",
    "        else:\n",
    "            all_item = df.apply(lambda x: eval(x['prev_items'].replace(\" \", \",\")), axis=1)\n",
    "    all_item_id = []\n",
    "    for x in all_item:\n",
    "        all_item_id.append([map_id(y, id_dict) for y in x])\n",
    "    return all_item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_pop(sess: list, ):\n",
    "    all_item_id = []\n",
    "    for s in train_sess_itemid:\n",
    "        all_item_id += s\n",
    "    return Counter(all_item_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_co_occurence_dict(sessions: list, bidirection: bool=True, weighted: bool=False) -> dict:\n",
    "    res = {}\n",
    "    for sess in tqdm(sessions):\n",
    "        for i, id in enumerate(sess):\n",
    "            if id not in res:\n",
    "                res[id] = Counter()\n",
    "            for j in range(i+1, len(sess)):\n",
    "                if not weighted:\n",
    "                    res[id][sess[j]] += 1\n",
    "                else:\n",
    "                    res[id][sess[j]] += 1 / (j-i)\n",
    "                if bidirection:\n",
    "                    if sess[j] not in res:\n",
    "                        res[sess[j]] = Counter()\n",
    "                    if not weighted:\n",
    "                        res[sess[j]][id] += 1\n",
    "                    else:\n",
    "                        res[sess[j]][id] += 1 / (j-i)\n",
    "    return res\n",
    "\n",
    "\n",
    "def convert_co_occurence_dict_to_matrix(co_occurence_dict: dict) -> ssp.csr_matrix:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_co_occurence_dict(co_occurence_dict: dict) -> dict:\n",
    "    res = {}\n",
    "    for k,v in co_occurence_dict.items():\n",
    "        res[k] = dict(sorted(v.items(), key=lambda item: -item[1]))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_co_occurence_dict(sess: list, sess_locale: list, id2locale: dict, co_occurence_dict: dict, topk: int, pred_with_last: bool=False, remove_hist: bool=False) -> list:\n",
    "    sorted_dict = sort_co_occurence_dict(co_occurence_dict)\n",
    "    res = []\n",
    "    for i, s in tqdm(enumerate(sess)):\n",
    "        locale = sess_locale[i]\n",
    "        if not pred_with_last:\n",
    "            cand = Counter()\n",
    "            for i,id in enumerate(s):\n",
    "                if id in sorted_dict:\n",
    "                    if id in sorted_dict:\n",
    "                        cand = cand + Counter({ k:sorted_dict[id][k] * (i / len(s)) for k in list(sorted_dict[id].keys()) } )\n",
    "            cand = sorted(cand.items(), key=lambda x: -x[1])\n",
    "            cand = [i[0] for i in cand]\n",
    "        else:\n",
    "            if s[-1] not in sorted_dict:\n",
    "                cand = []\n",
    "            else:\n",
    "                cand = list(sorted_dict[s[-1]].keys())\n",
    "\n",
    "        if remove_hist:\n",
    "            cand = [x for x in cand if x not in s]\n",
    "\n",
    "        cand = [x for x in cand if locale in id2locale[x]]\n",
    "\n",
    "        cand = cand[: min(len(cand), topk)]\n",
    "        res.append(cand)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_topk_with_popular_items(rec_list: list, topk: int, pop_items: list) -> list:\n",
    "    # TODO: remove duplicated items; add locale constraint\n",
    "    res = [None] * len(rec_list)\n",
    "    for i, l in enumerate(rec_list):\n",
    "        pad_len = topk - len(l)\n",
    "        if pad_len > 0:\n",
    "            pad_items = random.sample(pop_items, pad_len)\n",
    "            res[i] = l + pad_items\n",
    "        else:\n",
    "            res[i] = l\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id2predictions(pred: list, test_df: pd.DataFrame, id_dict: dict) -> pd.DataFrame:\n",
    "    id2product = {v:k for k,v in id_dict.items()}\n",
    "    assert len(pred) == test_df.shape[0]\n",
    "    product_pred = [None] * len(pred)\n",
    "    for i, l in enumerate(pred):\n",
    "        product_pred[i] = [id2product[x] for x in l]\n",
    "    res = pd.DataFrame()\n",
    "    res['locale'] = test_df['locale']\n",
    "    res['next_item_prediction'] = product_pred\n",
    "    return res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part1: Predict with Co-Occurrence Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/huangxu/Amazon-KDDCUP-23/simple_method\n",
      "../raw_data/products_train.csv\n"
     ]
    }
   ],
   "source": [
    "train_sess_data = read_train_data()\n",
    "test_sess_data = read_test_data(task)\n",
    "product = read_product_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map product id\n",
    "id_dict = { id: i+1 for i, id in enumerate(product['id'].unique()) }    # 0 saved for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "locale_info = product[['id', 'locale']].groupby('id')['locale'].agg(list)\n",
    "id2locale = {id_dict[x]: locale_info[x] for x in product['id'].unique()}\n",
    "test_locale = test_sess_data['locale'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sess_itemid = get_sessions(train_sess_data, id_dict)\n",
    "test_sess_itemid = get_sessions(test_sess_data, id_dict, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pop = get_item_pop(train_sess_itemid)\n",
    "test_pop = get_item_pop(test_sess_data)\n",
    "total_pop = train_pop + test_pop\n",
    "sorted_pop = sorted(total_pop.items(), key=lambda x:-x[1])\n",
    "pop_items_200 = [x[0] for x in sorted_pop[:200]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3606249/3606249 [00:50<00:00, 71406.69it/s] \n",
      "100%|██████████| 316971/316971 [00:03<00:00, 105193.21it/s]\n"
     ]
    }
   ],
   "source": [
    "co_occurence_dict_train = get_co_occurence_dict(train_sess_itemid, bidirection=False)\n",
    "co_occurence_dict_test = get_co_occurence_dict(test_sess_itemid, bidirection=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3923220/3923220 [00:53<00:00, 73556.13it/s] \n"
     ]
    }
   ],
   "source": [
    "co_occurence_dict = get_co_occurence_dict(train_sess_itemid + test_sess_itemid, bidirection=False, weighted=False)\n",
    "res_test = predict_with_co_occurence_dict(test_sess_itemid, test_locale, id2locale, co_occurence_dict_train, 100, True, True)\n",
    "res = pad_topk_with_popular_items(res_test, 100, pop_items_200)\n",
    "pred_res = id2predictions(res, test_sess_data, id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    316971.0\n",
       "mean        100.0\n",
       "std           0.0\n",
       "min         100.0\n",
       "25%         100.0\n",
       "50%         100.0\n",
       "75%         100.0\n",
       "max         100.0\n",
       "Name: next_item_prediction, dtype: float64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_res['next_item_prediction'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_res.to_parquet(f'submission_co_occurence_{task}.parquet', engine='pyarrow')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part2: Use neighbors in co-occurence graph to compute coverage\n",
    "- First we need a validation dataset\n",
    "- Then we should compare several stategies below:\n",
    "    - Undirected graph + predict with history items \n",
    "    - Undirected graph + predict with last item\n",
    "    - Directed graph + predict with history items \n",
    "    - Directed graph + predict with last item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_neighbors(sess: list, co_occurence_dict: dict, pred_with_last: bool=False) -> list:\n",
    "    sorted_dict = sort_co_occurence_dict(co_occurence_dict)\n",
    "    res = []\n",
    "    for i, s in tqdm(enumerate(sess), total=len(sess)):\n",
    "        if not pred_with_last:\n",
    "            cand = Counter()\n",
    "            for i,id in enumerate(s):\n",
    "                if id in sorted_dict:\n",
    "                    if id in sorted_dict:\n",
    "                        cand = cand + Counter({ k:sorted_dict[id][k] * (i / len(s)) for k in list(sorted_dict[id].keys()) } )\n",
    "            cand = sorted(cand.items(), key=lambda x: -x[1])\n",
    "            cand = [i[0] for i in cand]\n",
    "        else:\n",
    "            if s[-1] not in sorted_dict:\n",
    "                cand = []\n",
    "            else:\n",
    "                cand = list(sorted_dict[s[-1]].keys())\n",
    "\n",
    "        res.append(cand)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_hit(pred, ground_truth) -> float:\n",
    "    hit_num = 0\n",
    "    for i, l in enumerate(pred):\n",
    "        if ground_truth[i] in l:\n",
    "            hit_num += 1\n",
    "    return hit_num / len(ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df = pd.read_csv(\"../raw_data/sampled_train_data.csv\")\n",
    "test_df = pd.read_csv(\"../raw_data/sampled_test_data.csv\")\n",
    "product_info = read_product_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recstudio_data_to_ori_data(rec_df):\n",
    "    res = rec_df.groupby(\"sess_id\").agg(list)\n",
    "    res['next_item'] = res['product_id'].apply(lambda x: x[-1])\n",
    "    res['prev_items'] = res['product_id'].apply(lambda x: x[: -1])\n",
    "    res['locale'] = res['locale'].apply(lambda x:x[0])\n",
    "    res = res[['prev_items', 'next_item', 'locale']]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/huangxu/Amazon-KDDCUP-23/simple_method\n",
      "../raw_data/products_train.csv\n"
     ]
    }
   ],
   "source": [
    "data_type = 'all' # ['all', 'tune']\n",
    "train_sess_data_0 = pd.read_csv(f'../data_for_recstudio/{data_type}_task_1_train_inter_feat.csv')\n",
    "test_sess_data_0 = pd.read_csv(f'../data_for_recstudio/{data_type}_task_1_valid_inter_feat.csv')\n",
    "product = read_product_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sess_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>locale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>B005ZJTUXE</td>\n",
       "      <td>0</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>B005ZJTUXE</td>\n",
       "      <td>1</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>B00P8VIBBG</td>\n",
       "      <td>2</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>B07TVSL9TW</td>\n",
       "      <td>3</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>B09M8HSN22</td>\n",
       "      <td>0</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18321870</th>\n",
       "      <td>3557896</td>\n",
       "      <td>B09J4G565S</td>\n",
       "      <td>2</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18321871</th>\n",
       "      <td>3557896</td>\n",
       "      <td>B08K8LLFQ6</td>\n",
       "      <td>3</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18321872</th>\n",
       "      <td>3557897</td>\n",
       "      <td>B09ZLBFC7L</td>\n",
       "      <td>0</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18321873</th>\n",
       "      <td>3557897</td>\n",
       "      <td>B09ZL9PK6Q</td>\n",
       "      <td>1</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18321874</th>\n",
       "      <td>3557897</td>\n",
       "      <td>B09P3HR6KB</td>\n",
       "      <td>2</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18321875 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sess_id  product_id  timestamp locale\n",
       "0               0  B005ZJTUXE          0     FR\n",
       "1               0  B005ZJTUXE          1     FR\n",
       "2               0  B00P8VIBBG          2     FR\n",
       "3               0  B07TVSL9TW          3     FR\n",
       "4               1  B09M8HSN22          0     DE\n",
       "...           ...         ...        ...    ...\n",
       "18321870  3557896  B09J4G565S          2     UK\n",
       "18321871  3557896  B08K8LLFQ6          3     UK\n",
       "18321872  3557897  B09ZLBFC7L          0     UK\n",
       "18321873  3557897  B09ZL9PK6Q          1     UK\n",
       "18321874  3557897  B09P3HR6KB          2     UK\n",
       "\n",
       "[18321875 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sess_data_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df = recstudio_data_to_ori_data(train_sess_data_0)\n",
    "test_df = recstudio_data_to_ori_data(test_sess_data_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_dict = { id: i+1 for i, id in enumerate(product['id'].unique()) }    # 0 saved for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sess_itemid = get_sessions(trn_df, id_dict, list_item=True)\n",
    "test_sess_itemid = get_sessions(test_df, id_dict, test=True, list_item=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = [id_dict[x] for x in test_df['next_item'].tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undirected graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3557898/3557898 [00:51<00:00, 69489.03it/s]\n"
     ]
    }
   ],
   "source": [
    "co_occurence_dict_train = get_co_occurence_dict(train_sess_itemid, bidirection=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361581/361581 [03:28<00:00, 1734.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Ratio 0.555621008847257\n"
     ]
    }
   ],
   "source": [
    "# predict with all items in session\n",
    "pred_res = predict_with_neighbors(test_sess_itemid, co_occurence_dict_train, pred_with_last=False)\n",
    "print('Hit Ratio', (cal_hit(pred_res, ground_truth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of neighbors: Mean=251.27782433258383, Min=0, Max=11263\n"
     ]
    }
   ],
   "source": [
    "length = np.array([len(r) for r in pred_res])\n",
    "print(\"Length of neighbors: Mean={}, Min={}, Max={}\".format(length.mean(), length.min(), length.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 361581/361581 [00:07<00:00, 45882.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Ratio 0.5127813684900479\n"
     ]
    }
   ],
   "source": [
    "# predict with last item\n",
    "pred_res = predict_with_neighbors(test_sess_itemid, co_occurence_dict_train, pred_with_last=True)\n",
    "print('Hit Ratio', (cal_hit(pred_res, ground_truth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of neighbors: Mean=147.21013299170326, Min=0, Max=2989\n"
     ]
    }
   ],
   "source": [
    "length = np.array([len(r) for r in pred_res])\n",
    "print(\"Length of neighbors: Mean={}, Min={}, Max={}\".format(length.mean(), length.min(), length.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directed graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3245625/3245625 [00:54<00:00, 60052.64it/s] \n"
     ]
    }
   ],
   "source": [
    "co_occurence_dict_train = get_co_occurence_dict(train_sess_itemid, bidirection=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "360624it [03:38, 1651.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Ratio 0.5712487244332046\n"
     ]
    }
   ],
   "source": [
    "# predict with all items in session\n",
    "pred_res = predict_with_neighbors(test_sess_itemid, co_occurence_dict_train, pred_with_last=False)\n",
    "print('Hit Ratio', (cal_hit(pred_res, ground_truth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "360624it [00:04, 74615.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Ratio 0.5062364124406584\n"
     ]
    }
   ],
   "source": [
    "# predict with last item\n",
    "pred_res = predict_with_neighbors(test_sess_itemid, co_occurence_dict_train, pred_with_last=True)\n",
    "print('Hit Ratio', (cal_hit(pred_res, ground_truth)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part3: Generate each item's neighbors in co-occurence graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/huangxu/Amazon-KDDCUP-23/simple_method\n",
      "../raw_data/products_train.csv\n"
     ]
    }
   ],
   "source": [
    "# train_sess_data = read_train_data()\n",
    "# test_sess_data = read_test_data('task1')\n",
    "# product = read_product_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_product_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m train_sess_data_0 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../data_for_recstudio/\u001b[39m\u001b[39m{\u001b[39;00mdata_type\u001b[39m}\u001b[39;00m\u001b[39m_task_1_train_inter_feat.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m test_sess_data_0 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m../data_for_recstudio/\u001b[39m\u001b[39m{\u001b[39;00mdata_type\u001b[39m}\u001b[39;00m\u001b[39m_task_1_valid_inter_feat.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m product \u001b[39m=\u001b[39m read_product_data()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_product_data' is not defined"
     ]
    }
   ],
   "source": [
    "data_type = 'all' # ['all', 'tune']\n",
    "train_sess_data_0 = pd.read_csv(f'../data_for_recstudio/{data_type}_task_1_train_inter_feat.csv')\n",
    "test_sess_data_0 = pd.read_csv(f'../data_for_recstudio/{data_type}_task_1_valid_inter_feat.csv')\n",
    "product = read_product_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sess_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>locale</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>B09VSN9GLS</td>\n",
       "      <td>0</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>B09VSG9DCG</td>\n",
       "      <td>1</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>B0BJ5L1ZPH</td>\n",
       "      <td>2</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>B09VSN9GLS</td>\n",
       "      <td>3</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>B0BJ6V797Y</td>\n",
       "      <td>4</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>B09VSG9DCG</td>\n",
       "      <td>5</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>B077XGDMD2</td>\n",
       "      <td>6</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>B06XG1LZ6Z</td>\n",
       "      <td>7</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>B00390YWXE</td>\n",
       "      <td>0</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>B00390YWXE</td>\n",
       "      <td>1</td>\n",
       "      <td>JP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sess_id  product_id  timestamp locale\n",
       "0        0  B09VSN9GLS          0     UK\n",
       "1        0  B09VSG9DCG          1     UK\n",
       "2        0  B0BJ5L1ZPH          2     UK\n",
       "3        0  B09VSN9GLS          3     UK\n",
       "4        0  B0BJ6V797Y          4     UK\n",
       "5        0  B09VSG9DCG          5     UK\n",
       "6        0  B077XGDMD2          6     UK\n",
       "7        0  B06XG1LZ6Z          7     UK\n",
       "8        1  B00390YWXE          0     JP\n",
       "9        1  B00390YWXE          1     JP"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sess_data_0.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sess_data = train_sess_data_0.groupby(\"sess_id\").agg(list)\n",
    "test_sess_data = test_sess_data_0.groupby(\"sess_id\").agg(list)\n",
    "train_sess_data['locale'] = train_sess_data[\"locale\"].apply(lambda x: x[0])\n",
    "test_sess_data['locale'] = test_sess_data[\"locale\"].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sess_data = train_sess_data.rename(columns={'product_id': 'prev_items'})\n",
    "test_sess_data = test_sess_data.rename(columns={'product_id': 'prev_items'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map product id\n",
    "id_dict = { id: i+1 for i, id in enumerate(product['id'].unique()) }    # 0 saved for padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sess_itemid = get_sessions(train_sess_data, id_dict, list_item=True)\n",
    "test_sess_itemid = get_sessions(test_sess_data, id_dict, list_item=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pop = get_item_pop(train_sess_itemid)\n",
    "# test_pop = get_item_pop(test_sess_data)\n",
    "total_pop = train_pop\n",
    "sorted_pop = sorted(total_pop.items(), key=lambda x:-x[1])\n",
    "pop_items_500 = [x[0] for x in sorted_pop[:500]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undirected Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3557898/3557898 [00:40<00:00, 88601.73it/s]\n"
     ]
    }
   ],
   "source": [
    "co_occurence_dict = get_co_occurence_dict(train_sess_itemid, bidirection=False, weighted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dict_by_values(d: dict, desc=True) -> dict:\n",
    "    if desc:\n",
    "        res = sorted(d.items(), key=lambda x: -x[1])\n",
    "    else:\n",
    "        res = sorted(d.items(), key=lambda x: x[1])\n",
    "    return dict(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors_for_each_product(co_occurence_dict: dict, productid_map: dict, pop_products: list, k: int=300):\n",
    "    res = {'id': [], 'candidates_id': [], 'state': []}\n",
    "    for pid, id in tqdm(productid_map.items(), total=len(productid_map)):\n",
    "        if id in co_occurence_dict:\n",
    "            neighbors = list(sort_dict_by_values(co_occurence_dict[id]).keys())\n",
    "            if len(neighbors) >= k:\n",
    "                cands = neighbors[:k]\n",
    "                state = 'Full'\n",
    "            else:\n",
    "                _pop_cands = random.sample(pop_products, k-len(neighbors))\n",
    "                cands = neighbors + _pop_cands\n",
    "                state = 'Pad'\n",
    "        else:\n",
    "            cands = random.sample(pop_products, k)\n",
    "            state = 'No'\n",
    "        res['id'].append(pid)\n",
    "        res['candidates_id'].append(cands)\n",
    "        res['state'].append(state)\n",
    "    df = pd.DataFrame(res)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1410675/1410675 [02:33<00:00, 9209.77it/s]\n"
     ]
    }
   ],
   "source": [
    "neighbors_df = get_neighbors_for_each_product(co_occurence_dict, id_dict, pop_items_500, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2pid = {v:k for k,v in id_dict.items()}\n",
    "neighbors_df['candidates'] = neighbors_df['candidates_id'].apply(lambda x: [id2pid[_] for _ in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>candidates</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B005ZSSN10</td>\n",
       "      <td>[B005ZSSNXS, B07WD58H6R, B00NTCHCU2, B07QQZD49...</td>\n",
       "      <td>pad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B08PRYN6LD</td>\n",
       "      <td>[B08PSBK59Y, B005PKZK7S, B01M9EYRD1, B09K4HVP7...</td>\n",
       "      <td>pad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B09MBZJ48V</td>\n",
       "      <td>[B07VR16HF9, B089QVZBWM, B005HWEZGG, B07FL7GVZ...</td>\n",
       "      <td>pad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B08ZN6F26S</td>\n",
       "      <td>[B08PVG787Z, B08ZN6F26S, B07JKP79B6, B0002HR7W...</td>\n",
       "      <td>pad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B094DGRV7D</td>\n",
       "      <td>[B08KTP6517, B06WVS91VM, B094DGRV7D, B08KTN66X...</td>\n",
       "      <td>pad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                         candidates state\n",
       "0  B005ZSSN10  [B005ZSSNXS, B07WD58H6R, B00NTCHCU2, B07QQZD49...   pad\n",
       "1  B08PRYN6LD  [B08PSBK59Y, B005PKZK7S, B01M9EYRD1, B09K4HVP7...   pad\n",
       "2  B09MBZJ48V  [B07VR16HF9, B089QVZBWM, B005HWEZGG, B07FL7GVZ...   pad\n",
       "3  B08ZN6F26S  [B08PVG787Z, B08ZN6F26S, B07JKP79B6, B0002HR7W...   pad\n",
       "4  B094DGRV7D  [B08KTP6517, B06WVS91VM, B094DGRV7D, B08KTN66X...   pad"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors_df = neighbors_df[['id', 'candidates', 'state']]\n",
    "neighbors_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1410675.0\n",
       "mean         300.0\n",
       "std            0.0\n",
       "min          300.0\n",
       "25%          300.0\n",
       "50%          300.0\n",
       "75%          300.0\n",
       "max          300.0\n",
       "Name: candidates, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors_df['candidates'].apply(len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors_df.to_parquet(f'../co-orrurrence_graph/{data_type}_item_candidates.parquet', engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors_df.to_feather('../co-orrurrence_graph/{data_type}_item_candidates.ftr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors_df.to_csv('../co-orrurrence_graph/{data_type}_item_candidates.csv', index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huangxu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
