{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from functools import lru_cache\n",
    "import os\n",
    "from tqdm import tqdm \n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = '../raw_data/'\n",
    "test_data_dir = '../raw_data/'\n",
    "recstudio_data_dir = '../data_for_recstudio/'\n",
    "task = 'task1'\n",
    "PREDS_PER_SESSION = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=1)\n",
    "def read_product_data():\n",
    "    return pd.read_csv(os.path.join(train_data_dir, 'products_train.csv'))\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def read_train_data():\n",
    "    return pd.read_csv(os.path.join(train_data_dir, 'sessions_train.csv'))\n",
    "\n",
    "@lru_cache(maxsize=3)\n",
    "def read_test_data(task):\n",
    "    return pd.read_csv(os.path.join(test_data_dir, f'sessions_test_{task}.csv'))\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def read_all_task1_data():\n",
    "    return pd.read_csv(os.path.join(recstudio_data_dir, 'products_train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_valid_data(df, ratio):\n",
    "    num_sessions = len(df)\n",
    "    num_val_sessions = int(ratio * num_sessions)\n",
    "    index_permu = np.random.permutation(num_sessions)\n",
    "    valid_index = index_permu[:num_val_sessions]\n",
    "    train_index = index_permu[num_val_sessions:]\n",
    "    val_df = df.iloc[valid_index].reset_index(drop=True)\n",
    "    train_df = df.iloc[train_index].reset_index(drop=True)\n",
    "    return train_df, val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sessions = read_train_data()\n",
    "task_1_test_sessions = read_test_data('task1')\n",
    "task_3_test_sessions = read_test_data('task3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_3_test_sessions = task_3_test_sessions[task_3_test_sessions['locale'].isin(['UK', 'JP', 'DE'])].reset_index(drop=True)\n",
    "len(task_3_test_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 316971/316971 [00:47<00:00, 6678.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          prev_items locale   next_item\n",
      "0  ['B08V12CT4C' 'B08V1KXBQD' 'B01BVG1XJS' 'B09VC...     DE  B099NQFMG7\n",
      "1                        ['B00R9R5ND6' 'B00R9RZ9ZS']     DE  B00R9RZ9ZS\n",
      "2           ['B07YSRXJD3' 'B07G7Q5N6G' 'B08C9Q7QVK']     DE  B07G7Q5N6G\n",
      "3  ['B08KQBYV43' '3955350843' '3955350843' '39553...     DE  3955350843\n",
      "4  ['B09FPTCWMC' 'B09FPTQP68' 'B08HMRY8NG' 'B08TB...     DE  B09J945WQR\n",
      "316971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:04<00:00, 6723.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 prev_items locale   next_item\n",
      "0  ['B07KWVBK8W' 'B07KWVDNV2' 'B07KWVBK8W']     DE  B01M2CLQA5\n",
      "1               ['B08K7GPV1G' 'B08P1WJYW5']     DE  B09MFXKQMT\n",
      "2               ['B07R8RCRYL' 'B08379LSYF']     DE  B00PM9Z2L6\n",
      "3  ['B084RTW66R' 'B001O7XWFI' 'B088KRKFJ3']     DE  B09LYX3WBC\n",
      "4                            ['B074M9DZ4M']     DE  B074M9DZ4M\n",
      "30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# merge 3 data\n",
    "\n",
    "task1_prev_items, task1_locales, task1_next_items  = [], [], []\n",
    "for i in tqdm(range(len(task_1_test_sessions))):\n",
    "    sess = task_1_test_sessions.iloc[i]\n",
    "    sess_prev_items = sess['prev_items']\n",
    "    sess_locale = sess['locale']\n",
    "    product_list = sess_prev_items.strip('[]').split(' ')\n",
    "    product_list = np.array(list(map(lambda x : x.strip(\"'\\n\"), product_list)))\n",
    "    \n",
    "    if len(product_list) <= 1:\n",
    "        continue\n",
    "\n",
    "    next_item = product_list[-1]\n",
    "    product_list = product_list[:-1]\n",
    "\n",
    "    task1_prev_items.append(str(product_list))\n",
    "    task1_locales.append(sess_locale)\n",
    "    task1_next_items.append(next_item)\n",
    "\n",
    "task_1_test_sessions = pd.DataFrame({'prev_items' : task1_prev_items, 'locale' : task1_locales, 'next_item' : task1_next_items})\n",
    "print(task_1_test_sessions.head(5))\n",
    "print(len(task_1_test_sessions))\n",
    "\n",
    "task3_prev_items, task3_locales, task3_next_items  = [], [], []\n",
    "for i in tqdm(range(len(task_3_test_sessions))):\n",
    "    sess = task_3_test_sessions.iloc[i]\n",
    "    sess_prev_items = sess['prev_items']\n",
    "    sess_locale = sess['locale']\n",
    "    product_list = sess_prev_items.strip('[]').split(' ')\n",
    "    product_list = np.array(list(map(lambda x : x.strip(\"'\\n\"), product_list)))\n",
    "    \n",
    "    if len(product_list) <= 1:\n",
    "        continue\n",
    "\n",
    "    next_item = product_list[-1]\n",
    "    product_list = product_list[:-1]\n",
    "\n",
    "    task3_prev_items.append(str(product_list))\n",
    "    task3_locales.append(sess_locale)\n",
    "    task3_next_items.append(next_item)\n",
    "\n",
    "task_3_test_sessions = pd.DataFrame({'prev_items' : task3_prev_items, 'locale' : task3_locales, 'next_item' : task3_next_items})\n",
    "print(task_3_test_sessions.head(5))\n",
    "print(len(task_3_test_sessions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                          prev_items   next_item locale\n",
       " 0                        ['B09W9FND7K' 'B09JSPLN1M']  B09M7GY217     DE\n",
       " 1  ['B076THCGSG' 'B007MO8IME' 'B08MF65MLV' 'B001B...  B001B4THSA     DE\n",
       " 2  ['B0B1LGXWDS' 'B00AZYORS2' 'B0B1LGXWDS' 'B00AZ...  B0767DTG2Q     DE\n",
       " 3  ['B09XMTWDVT' 'B0B4MZZ8MB' 'B0B7HZ2GWX' 'B09XM...  B0B4R9NN4B     DE\n",
       " 4           ['B09Y5CSL3T' 'B09Y5DPTXN' 'B09FKD61R8']  B0BGVBKWGZ     DE,\n",
       " 3953220,\n",
       " 3606249)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_task_1_sessions = pd.concat([train_sessions, task_1_test_sessions, task_3_test_sessions], axis=0, ignore_index=True)\n",
    "all_task_1_sessions.head(5), len(all_task_1_sessions), len(train_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split all data \n",
    "all_task_1_train_sessions, all_task_1_valid_sessions = split_valid_data(all_task_1_sessions, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3557898, 395322)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_task_1_train_sessions), len(all_task_1_valid_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "361581"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter ES, IT, FR in valid sessions\n",
    "all_task_1_valid_sessions = all_task_1_valid_sessions[all_task_1_valid_sessions['locale'].isin(['DE', 'JP', 'UK'])]\n",
    "len(all_task_1_valid_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def session_2_inter_feat(sessions_df, save_path):\n",
    "    num_sessions = len(sessions_df)\n",
    "\n",
    "    with open(os.path.join(save_path), 'w') as f:\n",
    "        f.write('sess_id,product_id,timestamp,locale\\n')\n",
    "\n",
    "        for i in tqdm(range(num_sessions)):\n",
    "            sess = sessions_df.iloc[i]\n",
    "            sess_locale = sess['locale']\n",
    "            sess_prev_items = sess['prev_items']\n",
    "            sess_next_item = sess['next_item']\n",
    "            \n",
    "            product_list = sess_prev_items.strip('[]').split(' ')\n",
    "            product_list = list(map(lambda x : x.strip(\"'\\n\"), product_list))\n",
    "            product_list.append(sess_next_item)\n",
    "\n",
    "            sess_id = i\n",
    "            for j, product_id in enumerate(product_list):\n",
    "                inter_str = f'{sess_id},{product_id},{j},{sess_locale}\\n'\n",
    "                f.write(inter_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3557898/3557898 [05:45<00:00, 10285.57it/s]\n",
      "100%|██████████| 361581/361581 [00:35<00:00, 10151.82it/s]\n"
     ]
    }
   ],
   "source": [
    "session_2_inter_feat(all_task_1_train_sessions, '../data_for_recstudio/all_task_1_train_inter_feat.csv')\n",
    "session_2_inter_feat(all_task_1_valid_sessions, '../data_for_recstudio/all_task_1_valid_inter_feat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_task_1_sessions = all_task_1_sessions.sample(int(0.3 * len(all_task_1_sessions)), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1185966"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tune_task_1_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1067370, 118596)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_task_1_train_sessions, tune_task_1_valid_sessions = split_valid_data(tune_task_1_sessions, 0.1)\n",
    "len(tune_task_1_train_sessions), len(tune_task_1_valid_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108617"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter ES, IT, FR in valid sessions\n",
    "tune_task_1_valid_sessions = tune_task_1_valid_sessions[tune_task_1_valid_sessions['locale'].isin(['DE', 'JP', 'UK'])]\n",
    "len(tune_task_1_valid_sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1067370/1067370 [01:42<00:00, 10365.51it/s]\n",
      "100%|██████████| 108617/108617 [00:10<00:00, 10113.86it/s]\n"
     ]
    }
   ],
   "source": [
    "session_2_inter_feat(tune_task_1_train_sessions, '../data_for_recstudio/tune_task_1_train_inter_feat.csv')\n",
    "session_2_inter_feat(tune_task_1_valid_sessions, '../data_for_recstudio/tune_task_1_valid_inter_feat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18321875, 1882412)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_task_1_train_inter_feat = pd.read_csv('../data_for_recstudio/all_task_1_train_inter_feat.csv')\n",
    "all_task_1_valid_inter_feat = pd.read_csv('../data_for_recstudio/all_task_1_valid_inter_feat.csv')\n",
    "\n",
    "len(all_task_1_train_inter_feat), len(all_task_1_valid_inter_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5497807, 566614)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_task_1_train_inter_feat = pd.read_csv('../data_for_recstudio/tune_task_1_train_inter_feat.csv')\n",
    "tune_task_1_valid_inter_feat = pd.read_csv('../data_for_recstudio/tune_task_1_valid_inter_feat.csv')\n",
    "len(tune_task_1_train_inter_feat), len(tune_task_1_valid_inter_feat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
