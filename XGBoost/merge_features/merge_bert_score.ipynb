{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use loc[i, field] instead of iloc[i, field], iloc is very slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/xiaolong/anaconda3/envs/pytorch_gpu/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path = ['/root/autodl-tmp/xiaolong/WorkSpace/Amazon-KDDCUP-23/RecStudio/'] + sys.path\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cudf, itertools\n",
    "import scipy.sparse as ssp\n",
    "from functools import lru_cache, partial\n",
    "from tqdm import tqdm, trange\n",
    "from collections import Counter, defaultdict\n",
    "import torch\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cast_dtype(df : pd.DataFrame, columns=None):\n",
    "    if columns is None:\n",
    "        columns = df.columns\n",
    "    for k in columns:\n",
    "        dt = type(df[k].iloc[0])\n",
    "        if 'float' in str(dt):\n",
    "            df[k] = df[k].astype('float32')\n",
    "        elif 'int' in str(dt):\n",
    "            df[k] = df[k].astype('int32')\n",
    "        elif dt == list:\n",
    "            dt_ = type(df.iloc[0][k][0])\n",
    "            if 'float' in str(dt_):\n",
    "                df[k] = df[k].apply(lambda x : np.array(x, dtype=np.float32))\n",
    "            elif 'int' in str(dt_):\n",
    "                df[k] = df[k].apply(lambda x : np.array(x, dtype=np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_cache(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        download_obj = pickle.load(f)\n",
    "    return download_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(merged_candidates_df, query_embeddings, product_embeddings):\n",
    "    batch_size = 2048\n",
    "    num_iter = (len(merged_candidates_df) - 1) // batch_size + 1\n",
    "    score_list = []\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(num_iter)):\n",
    "            st, ed = i * batch_size, (i + 1) * batch_size \n",
    "            batch_sess = merged_candidates_df.iloc[st : ed]\n",
    "            batch_sess_id = torch.tensor(batch_sess['sess_id'].tolist(), dtype=torch.long, device=query_embeddings.device)\n",
    "            batch_product_id = torch.tensor(batch_sess['dataset_id'].tolist(), dtype=torch.long, device=product_embeddings.device)\n",
    "            query_emb = query_embeddings[batch_sess_id].to('cuda:0')\n",
    "            product_emb = product_embeddings[batch_product_id].to('cuda:0')\n",
    "            batch_score = (query_emb * product_emb).sum(dim=-1) \n",
    "            score_list.append(batch_score.cpu())\n",
    "        score_list = torch.cat(score_list, dim=0).cpu().tolist()\n",
    "        return score_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_scores(score_df, score_name, normalized_score_name):\n",
    "    # score_df_g = cudf.from_pandas(score_df)\n",
    "    score_df['exp_score'] = np.exp(score_df[score_name].to_numpy())\n",
    "    scores_sum = score_df[['sess_id', 'exp_score']].groupby('sess_id').sum()\n",
    "    scores_sum.reset_index(inplace=True)\n",
    "    scores_sum = scores_sum.sort_values(by=['sess_id'], ascending=True)\n",
    "    scores_sum.reset_index(drop=True, inplace=True)\n",
    "    scores_sum.rename(columns={'exp_score' : 'score_sum'}, inplace=True)\n",
    "\n",
    "    merged_score_df = score_df.merge(scores_sum, how='left', left_on=['sess_id'], right_on=['sess_id'])\n",
    "    merged_score_df = merged_score_df.sort_values(by=['sess_id', 'product'])\n",
    "    merged_score_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # merged_score_df = merged_score_df_g.to_pandas(merged_score_df_g)\n",
    "    score_df[normalized_score_name] = merged_score_df['exp_score'] / merged_score_df['score_sum']\n",
    "    score_df['exp_score'] = merged_score_df['exp_score']\n",
    "    score_df['score_sum'] = merged_score_df['score_sum']\n",
    "\n",
    "    # del scores_sum_g\n",
    "    # del merged_score_df_g "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge valid score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_candidates_feature_path = '/root/autodl-tmp/xiaolong/WorkSpace/Amazon-KDDCUP-23/XGBoost/candidates/merged_candidates_feature.parquet'\n",
    "valid_sessions_path = '/root/autodl-tmp/xiaolong/WorkSpace/Amazon-KDDCUP-23/data_for_recstudio/task1_data/task13_4_task1_valid_sessions.csv'\n",
    "test_sessions_path = '/root/autodl-tmp/xiaolong/WorkSpace/Amazon-KDDCUP-23/raw_data/sessions_test_task1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=1)\n",
    "def read_merged_candidates_feature():\n",
    "    return pd.read_parquet(merged_candidates_feature_path, engine='pyarrow')\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def read_valid_sessions():\n",
    "    return pd.read_csv(valid_sessions_path)\n",
    "\n",
    "@lru_cache(maxsize=1)\n",
    "def read_test_sessions():\n",
    "    return pd.read_csv(test_sessions_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIELD_NAME = 'bert_scores'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE_product_embeddings_path = '/root/autodl-tmp/xiaolong/WorkSpace/Amazon-KDDCUP-23/text_method/phase2_task1_bert_results_DE/results/item_reps/reordered_item.npy'\n",
    "DE_valid_embeddings_path = '/root/autodl-tmp/xiaolong/WorkSpace/Amazon-KDDCUP-23/text_method/phase2_task1_bert_results_DE/valid_results/valid_query_reps/query.npy'\n",
    "JP_product_embeddings_path = '/root/autodl-tmp/xiaolong/WorkSpace/Amazon-KDDCUP-23/text_method/phase2_task1_bert_results_JP/results/item_reps/reordered_item.npy'\n",
    "JP_valid_embeddings_path = '/root/autodl-tmp/xiaolong/WorkSpace/Amazon-KDDCUP-23/text_method/phase2_task1_bert_results_JP/valid_results/valid_query_reps/query.npy'\n",
    "UK_product_embeddings_path = '/root/autodl-tmp/xiaolong/WorkSpace/Amazon-KDDCUP-23/text_method/phase2_task1_roberta_results_UK/results/item_reps/reordered_item.npy'\n",
    "UK_valid_embeddings_path = '/root/autodl-tmp/xiaolong/WorkSpace/Amazon-KDDCUP-23/text_method/phase2_task1_roberta_results_UK/valid_results/valid_query_reps/query.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE_dataset_cache = '/root/autodl-tmp/xiaolong/WorkSpace/Amazon-KDDCUP-23/.recstudio/cache/cf49a486c59e9dd4de37544db3d11d4f'\n",
    "JP_dataset_cache = '/root/autodl-tmp/xiaolong/WorkSpace/Amazon-KDDCUP-23/.recstudio/cache/0a61def413f0594014cbda0db39a5d35'\n",
    "UK_dataset_cache = '/root/autodl-tmp/xiaolong/WorkSpace/Amazon-KDDCUP-23/.recstudio/cache/5bd28611fbebac9d3034ecb047ad8235'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE_train_dataset, DE_valid_dataset = _load_cache(DE_dataset_cache)\n",
    "JP_train_dataset, JP_valid_dataset = _load_cache(JP_dataset_cache)\n",
    "UK_train_dataset, UK_valid_dataset = _load_cache(UK_dataset_cache)\n",
    "locale_map = {\n",
    "    'DE' : DE_train_dataset.field2token2idx['product_id'], \n",
    "    'JP' : JP_train_dataset.field2token2idx['product_id'], \n",
    "    'UK' : UK_train_dataset.field2token2idx['product_id']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_candidates = read_merged_candidates_feature()\n",
    "valid_sessions = read_valid_sessions()\n",
    "EMBED_DIM = 768\n",
    "merged_candidates.sort_values(by=['sess_id', 'product'], inplace=True)\n",
    "merged_candidates.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess embeddings \n",
    "valid_DE_query_emb = torch.from_numpy(np.load(DE_valid_embeddings_path)) \n",
    "valid_JP_query_emb = torch.from_numpy(np.load(JP_valid_embeddings_path))\n",
    "valid_UK_query_emb = torch.from_numpy(np.load(UK_valid_embeddings_path))\n",
    "valid_query_embeddings = torch.empty(len(valid_sessions), EMBED_DIM)\n",
    "valid_query_embeddings[(valid_sessions[valid_sessions['locale'] == 'DE'].index).tolist()] = valid_DE_query_emb\n",
    "valid_query_embeddings[(valid_sessions[valid_sessions['locale'] == 'JP'].index).tolist()] = valid_JP_query_emb\n",
    "valid_query_embeddings[(valid_sessions[valid_sessions['locale'] == 'UK'].index).tolist()] = valid_UK_query_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0282,  0.0774, -0.1366,  ...,  0.1535, -0.0135,  0.0947],\n",
       "         [-0.1326,  0.1515, -0.3750,  ...,  0.0164, -0.1484, -0.1188],\n",
       "         [ 0.0509,  0.1774, -0.1938,  ..., -0.2617,  0.0409,  0.1053],\n",
       "         ...,\n",
       "         [-0.0287,  0.3558,  0.3159,  ..., -0.1061,  0.0198, -0.0101],\n",
       "         [ 0.0265,  0.5761,  0.1858,  ..., -0.0052, -0.0693, -0.0411],\n",
       "         [-0.2727,  0.4056, -0.1167,  ...,  0.2551, -0.1521,  0.1274]]),\n",
       " torch.Size([361581, 768]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_query_embeddings, valid_query_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# product_embeddings, the embeddings include padding embedding\n",
    "DE_product_emb = torch.from_numpy(np.load(DE_product_embeddings_path)).type(torch.float)\n",
    "JP_product_emb = torch.from_numpy(np.load(JP_product_embeddings_path)).type(torch.float)\n",
    "UK_product_emb = torch.from_numpy(np.load(UK_product_embeddings_path)).type(torch.float)\n",
    "product_embeddings = torch.cat([DE_product_emb, JP_product_emb, UK_product_emb], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.2777,  0.4617,  0.1657,  ...,  0.0505,  0.0628, -0.7108],\n",
       "        [-0.0915,  0.2569, -0.1503,  ..., -0.0563,  0.1256, -0.4411],\n",
       "        ...,\n",
       "        [ 0.2559,  0.1071, -0.1689,  ..., -0.0935, -0.0517, -0.4844],\n",
       "        [-0.1851,  0.6337,  0.0548,  ...,  0.1978, -0.4778, -0.8956],\n",
       "        [-0.1200,  0.1002, -0.4467,  ...,  0.1571, -0.4825, -0.3066]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DE_product_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_candidates_ = merged_candidates[['sess_id', 'sess_locale', 'product']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "DE_product_list, DE_id_list = list(zip(*locale_map['DE'].items()))\n",
    "JP_product_list, JP_id_list = list(zip(*locale_map['JP'].items()))\n",
    "UK_product_list, UK_id_list = list(zip(*locale_map['UK'].items()))\n",
    "product_list = list(DE_product_list) + list(JP_product_list) + list(UK_product_list)\n",
    "id_list = list(DE_id_list) + list(JP_id_list) + list(UK_id_list)\n",
    "locale_list = ['DE'] * len(DE_id_list) + ['JP'] * len(JP_id_list) + ['UK'] * len(UK_id_list)\n",
    "product_id_df = pd.DataFrame({'locale' : locale_list, 'product' : product_list, 'dataset_id' : id_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_candidates_g = cudf.from_pandas(merged_candidates_)\n",
    "# product_id_df_g = cudf.from_pandas(product_id_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_candidates_score_g = merged_candidates_g.merge(product_id_df_g, how='left', left_on=['sess_locale', 'product'], right_on=['locale', 'product'])\n",
    "# merged_candidates_score_g['dataset_id'] = merged_candidates_score_g['dataset_id'].fillna(0)\n",
    "# merged_candidates_score_g.drop(columns=['locale'], inplace=True)\n",
    "# merged_candidates_score_g = merged_candidates_score_g.sort_values(by=['sess_id', 'product'])\n",
    "# merged_candidates_score_g.reset_index(drop=True, inplace=True)\n",
    "# merged_candidates_score = merged_candidates_score_g.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_candidates_score = merged_candidates_.merge(product_id_df, how='left', left_on=['sess_locale', 'product'], right_on=['locale', 'product'])\n",
    "merged_candidates_score['dataset_id'] = merged_candidates_score['dataset_id'].fillna(0)\n",
    "merged_candidates_score.drop(columns=['locale'], inplace=True)\n",
    "merged_candidates_score = merged_candidates_score.sort_values(by=['sess_id', 'product'])\n",
    "merged_candidates_score.reset_index(drop=True, inplace=True)\n",
    "assert len(merged_candidates_score) == len(merged_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del merged_candidates_g\n",
    "# del product_id_df_g\n",
    "# del merged_candidates_score_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_410892/2978421209.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_candidates_score['dataset_id'][merged_candidates_score['sess_locale'] == locale] = \\\n"
     ]
    }
   ],
   "source": [
    "locale_offset = {'DE' : 0, 'JP' : len(DE_product_list), 'UK' : len(DE_product_list) + len(JP_product_list)}\n",
    "for locale in ['DE', 'JP', 'UK']:\n",
    "    merged_candidates_score['dataset_id'][merged_candidates_score['sess_locale'] == locale] = \\\n",
    "        merged_candidates_score['dataset_id'][merged_candidates_score['sess_locale'] == locale] + locale_offset[locale]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using cosine scores \n",
    "normalized_valid_query_embeddings = torch.nn.functional.normalize(valid_query_embeddings, p=2, dim=-1)\n",
    "normalized_product_embeddings = torch.nn.functional.normalize(product_embeddings, p=2, dim=-1)\n",
    "normalized_product_embeddings = normalized_product_embeddings.type(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/37877 [00:00<?, ?it/s]/tmp/ipykernel_410892/622120297.py:10: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  batch_product_id = torch.tensor(batch_sess['dataset_id'].tolist(), dtype=torch.long, device=product_embeddings.device)\n",
      "100%|██████████| 37877/37877 [03:14<00:00, 194.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# cosine scores\n",
    "merged_candidates_score['cos_'+FIELD_NAME] = get_scores(merged_candidates_score, normalized_valid_query_embeddings, normalized_product_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/37877 [00:00<?, ?it/s]/tmp/ipykernel_410892/622120297.py:10: DeprecationWarning: an integer is required (got type float).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  batch_product_id = torch.tensor(batch_sess['dataset_id'].tolist(), dtype=torch.long, device=product_embeddings.device)\n",
      "100%|██████████| 37877/37877 [03:07<00:00, 202.28it/s]\n"
     ]
    }
   ],
   "source": [
    "merged_candidates_score[FIELD_NAME] = get_scores(merged_candidates_score, valid_query_embeddings, product_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize_scores(merged_candidates_score, FIELD_NAME, 'normalized_'+FIELD_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_candidates['cos_'+FIELD_NAME] = merged_candidates_score['cos_'+FIELD_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_candidates[FIELD_NAME] = merged_candidates_score[FIELD_NAME]\n",
    "merged_candidates['normalized_'+FIELD_NAME] = merged_candidates_score['normalized_'+FIELD_NAME]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cast_dtype(merged_candidates, ['cos_'+FIELD_NAME])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cast_dtype(merged_candidates, [FIELD_NAME, 'normalized_'+FIELD_NAME])\n",
    "merged_candidates.to_parquet(merged_candidates_feature_path, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sess_locale</th>\n",
       "      <th>product</th>\n",
       "      <th>normalized_sasrec_scores_2</th>\n",
       "      <th>sasrec_scores_2</th>\n",
       "      <th>normalized_bert_scores</th>\n",
       "      <th>cos_bert_scores</th>\n",
       "      <th>bert_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32168671</th>\n",
       "      <td>JP</td>\n",
       "      <td>B07QJWZWXL</td>\n",
       "      <td>0.132920</td>\n",
       "      <td>15.212090</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.947035</td>\n",
       "      <td>185.950150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168750</th>\n",
       "      <td>JP</td>\n",
       "      <td>B09HPP2P62</td>\n",
       "      <td>0.111624</td>\n",
       "      <td>15.037471</td>\n",
       "      <td>0.005894</td>\n",
       "      <td>0.954957</td>\n",
       "      <td>185.657837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168709</th>\n",
       "      <td>JP</td>\n",
       "      <td>B08LGXL3KL</td>\n",
       "      <td>0.075404</td>\n",
       "      <td>14.645205</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.937566</td>\n",
       "      <td>182.672867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168670</th>\n",
       "      <td>JP</td>\n",
       "      <td>B07QCL7FHC</td>\n",
       "      <td>0.073910</td>\n",
       "      <td>14.625184</td>\n",
       "      <td>0.026392</td>\n",
       "      <td>0.959379</td>\n",
       "      <td>187.157013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168828</th>\n",
       "      <td>JP</td>\n",
       "      <td>B0B71HWNBQ</td>\n",
       "      <td>0.072561</td>\n",
       "      <td>14.606762</td>\n",
       "      <td>0.003284</td>\n",
       "      <td>0.952611</td>\n",
       "      <td>185.073151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168714</th>\n",
       "      <td>JP</td>\n",
       "      <td>B08P57HNCJ</td>\n",
       "      <td>0.060838</td>\n",
       "      <td>14.430552</td>\n",
       "      <td>0.001012</td>\n",
       "      <td>0.919057</td>\n",
       "      <td>183.896027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168698</th>\n",
       "      <td>JP</td>\n",
       "      <td>B08937YX6R</td>\n",
       "      <td>0.057737</td>\n",
       "      <td>14.378245</td>\n",
       "      <td>0.008227</td>\n",
       "      <td>0.948958</td>\n",
       "      <td>185.991364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168640</th>\n",
       "      <td>JP</td>\n",
       "      <td>B015ZFKLNK</td>\n",
       "      <td>0.029743</td>\n",
       "      <td>13.714950</td>\n",
       "      <td>0.018403</td>\n",
       "      <td>0.949049</td>\n",
       "      <td>186.796448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168783</th>\n",
       "      <td>JP</td>\n",
       "      <td>B09WCKD74Q</td>\n",
       "      <td>0.028454</td>\n",
       "      <td>13.670612</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>0.945784</td>\n",
       "      <td>185.011200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168681</th>\n",
       "      <td>JP</td>\n",
       "      <td>B07Y421Y1S</td>\n",
       "      <td>0.027272</td>\n",
       "      <td>13.628181</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.936420</td>\n",
       "      <td>182.999954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168691</th>\n",
       "      <td>JP</td>\n",
       "      <td>B085C5H9DP</td>\n",
       "      <td>0.025772</td>\n",
       "      <td>13.571627</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>0.943976</td>\n",
       "      <td>184.899338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168845</th>\n",
       "      <td>JP</td>\n",
       "      <td>B0BC3M8BRQ</td>\n",
       "      <td>0.017387</td>\n",
       "      <td>13.178041</td>\n",
       "      <td>0.014261</td>\n",
       "      <td>0.949789</td>\n",
       "      <td>186.541458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168840</th>\n",
       "      <td>JP</td>\n",
       "      <td>B0BBM73LW5</td>\n",
       "      <td>0.014970</td>\n",
       "      <td>13.028399</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0.944096</td>\n",
       "      <td>185.362000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168816</th>\n",
       "      <td>JP</td>\n",
       "      <td>B0B42DPN21</td>\n",
       "      <td>0.014263</td>\n",
       "      <td>12.979996</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.932256</td>\n",
       "      <td>183.544632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168833</th>\n",
       "      <td>JP</td>\n",
       "      <td>B0B84YJMWB</td>\n",
       "      <td>0.014035</td>\n",
       "      <td>12.963921</td>\n",
       "      <td>0.016479</td>\n",
       "      <td>0.947297</td>\n",
       "      <td>186.686066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168676</th>\n",
       "      <td>JP</td>\n",
       "      <td>B07VHJZQYB</td>\n",
       "      <td>0.013911</td>\n",
       "      <td>12.955016</td>\n",
       "      <td>0.016404</td>\n",
       "      <td>0.951930</td>\n",
       "      <td>186.681503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168679</th>\n",
       "      <td>JP</td>\n",
       "      <td>B07W1JW15T</td>\n",
       "      <td>0.013829</td>\n",
       "      <td>12.949127</td>\n",
       "      <td>0.026245</td>\n",
       "      <td>0.957084</td>\n",
       "      <td>187.151428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168781</th>\n",
       "      <td>JP</td>\n",
       "      <td>B09W8RKQRW</td>\n",
       "      <td>0.013282</td>\n",
       "      <td>12.908739</td>\n",
       "      <td>0.006067</td>\n",
       "      <td>0.951615</td>\n",
       "      <td>185.686874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168740</th>\n",
       "      <td>JP</td>\n",
       "      <td>B09C7BY8Y8</td>\n",
       "      <td>0.011234</td>\n",
       "      <td>12.741273</td>\n",
       "      <td>0.001785</td>\n",
       "      <td>0.944957</td>\n",
       "      <td>184.463501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168731</th>\n",
       "      <td>JP</td>\n",
       "      <td>B093K6JBK9</td>\n",
       "      <td>0.010491</td>\n",
       "      <td>12.672853</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.936960</td>\n",
       "      <td>183.563538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168645</th>\n",
       "      <td>JP</td>\n",
       "      <td>B01KSZ3F8A</td>\n",
       "      <td>0.008548</td>\n",
       "      <td>12.468023</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.926998</td>\n",
       "      <td>181.877853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168672</th>\n",
       "      <td>JP</td>\n",
       "      <td>B07R5Q4R48</td>\n",
       "      <td>0.008478</td>\n",
       "      <td>12.459774</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.936312</td>\n",
       "      <td>185.071381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168634</th>\n",
       "      <td>JP</td>\n",
       "      <td>B0078ZTWP4</td>\n",
       "      <td>0.008384</td>\n",
       "      <td>12.448663</td>\n",
       "      <td>0.008421</td>\n",
       "      <td>0.955308</td>\n",
       "      <td>186.014709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168704</th>\n",
       "      <td>JP</td>\n",
       "      <td>B08F3SMVRZ</td>\n",
       "      <td>0.007249</td>\n",
       "      <td>12.303175</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.946985</td>\n",
       "      <td>184.839890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32168836</th>\n",
       "      <td>JP</td>\n",
       "      <td>B0B8N9CV5Q</td>\n",
       "      <td>0.006879</td>\n",
       "      <td>12.250757</td>\n",
       "      <td>0.007470</td>\n",
       "      <td>0.951973</td>\n",
       "      <td>185.894897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sess_locale     product  normalized_sasrec_scores_2  sasrec_scores_2  \\\n",
       "32168671          JP  B07QJWZWXL                    0.132920        15.212090   \n",
       "32168750          JP  B09HPP2P62                    0.111624        15.037471   \n",
       "32168709          JP  B08LGXL3KL                    0.075404        14.645205   \n",
       "32168670          JP  B07QCL7FHC                    0.073910        14.625184   \n",
       "32168828          JP  B0B71HWNBQ                    0.072561        14.606762   \n",
       "32168714          JP  B08P57HNCJ                    0.060838        14.430552   \n",
       "32168698          JP  B08937YX6R                    0.057737        14.378245   \n",
       "32168640          JP  B015ZFKLNK                    0.029743        13.714950   \n",
       "32168783          JP  B09WCKD74Q                    0.028454        13.670612   \n",
       "32168681          JP  B07Y421Y1S                    0.027272        13.628181   \n",
       "32168691          JP  B085C5H9DP                    0.025772        13.571627   \n",
       "32168845          JP  B0BC3M8BRQ                    0.017387        13.178041   \n",
       "32168840          JP  B0BBM73LW5                    0.014970        13.028399   \n",
       "32168816          JP  B0B42DPN21                    0.014263        12.979996   \n",
       "32168833          JP  B0B84YJMWB                    0.014035        12.963921   \n",
       "32168676          JP  B07VHJZQYB                    0.013911        12.955016   \n",
       "32168679          JP  B07W1JW15T                    0.013829        12.949127   \n",
       "32168781          JP  B09W8RKQRW                    0.013282        12.908739   \n",
       "32168740          JP  B09C7BY8Y8                    0.011234        12.741273   \n",
       "32168731          JP  B093K6JBK9                    0.010491        12.672853   \n",
       "32168645          JP  B01KSZ3F8A                    0.008548        12.468023   \n",
       "32168672          JP  B07R5Q4R48                    0.008478        12.459774   \n",
       "32168634          JP  B0078ZTWP4                    0.008384        12.448663   \n",
       "32168704          JP  B08F3SMVRZ                    0.007249        12.303175   \n",
       "32168836          JP  B0B8N9CV5Q                    0.006879        12.250757   \n",
       "\n",
       "          normalized_bert_scores  cos_bert_scores  bert_scores  \n",
       "32168671                0.007895         0.947035   185.950150  \n",
       "32168750                0.005894         0.954957   185.657837  \n",
       "32168709                0.000298         0.937566   182.672867  \n",
       "32168670                0.026392         0.959379   187.157013  \n",
       "32168828                0.003284         0.952611   185.073151  \n",
       "32168714                0.001012         0.919057   183.896027  \n",
       "32168698                0.008227         0.948958   185.991364  \n",
       "32168640                0.018403         0.949049   186.796448  \n",
       "32168783                0.003087         0.945784   185.011200  \n",
       "32168681                0.000413         0.936420   182.999954  \n",
       "32168691                0.002760         0.943976   184.899338  \n",
       "32168845                0.014261         0.949789   186.541458  \n",
       "32168840                0.004384         0.944096   185.362000  \n",
       "32168816                0.000712         0.932256   183.544632  \n",
       "32168833                0.016479         0.947297   186.686066  \n",
       "32168676                0.016404         0.951930   186.681503  \n",
       "32168679                0.026245         0.957084   187.151428  \n",
       "32168781                0.006067         0.951615   185.686874  \n",
       "32168740                0.001785         0.944957   184.463501  \n",
       "32168731                0.000726         0.936960   183.563538  \n",
       "32168645                0.000135         0.926998   181.877853  \n",
       "32168672                0.003279         0.936312   185.071381  \n",
       "32168634                0.008421         0.955308   186.014709  \n",
       "32168704                0.002601         0.946985   184.839890  \n",
       "32168836                0.007470         0.951973   185.894897  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify gru4rec scores\n",
    "merged_candidates[merged_candidates['sess_id'] == 150009].sort_values(by=['sasrec_scores_2'], ascending=False)[['sess_locale', 'product', 'normalized_sasrec_scores_2', 'sasrec_scores_2', 'normalized_bert_scores', 'cos_bert_scores', 'bert_scores']].iloc[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sess_id</th>\n",
       "      <th>sess_locale</th>\n",
       "      <th>product</th>\n",
       "      <th>target</th>\n",
       "      <th>sess_avg_price</th>\n",
       "      <th>product_price</th>\n",
       "      <th>product_freq</th>\n",
       "      <th>sasrec_scores_2</th>\n",
       "      <th>normalized_sasrec_scores_2</th>\n",
       "      <th>sasrec_scores_3</th>\n",
       "      <th>...</th>\n",
       "      <th>roberta_scores</th>\n",
       "      <th>normalized_roberta_scores</th>\n",
       "      <th>co_graph_counts_0</th>\n",
       "      <th>normalized_co_graph_counts_0</th>\n",
       "      <th>co_graph_counts_1</th>\n",
       "      <th>normalized_co_graph_counts_1</th>\n",
       "      <th>co_graph_counts_2</th>\n",
       "      <th>normalized_co_graph_counts_2</th>\n",
       "      <th>bert_scores</th>\n",
       "      <th>normalized_bert_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>UK</td>\n",
       "      <td>B000V599Y2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.388571</td>\n",
       "      <td>5.200000</td>\n",
       "      <td>37.0</td>\n",
       "      <td>13.152878</td>\n",
       "      <td>7.433639e-04</td>\n",
       "      <td>10.677187</td>\n",
       "      <td>...</td>\n",
       "      <td>259.157867</td>\n",
       "      <td>1.341519e-06</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.004992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>476.148773</td>\n",
       "      <td>8.255889e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>UK</td>\n",
       "      <td>B007VZUA7U</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.388571</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.393598</td>\n",
       "      <td>1.732076e-05</td>\n",
       "      <td>8.838863</td>\n",
       "      <td>...</td>\n",
       "      <td>257.981598</td>\n",
       "      <td>4.137609e-07</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.004992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>475.083313</td>\n",
       "      <td>2.844725e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>UK</td>\n",
       "      <td>B009EUAEQC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.388571</td>\n",
       "      <td>7.490000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.754339</td>\n",
       "      <td>1.835794e-04</td>\n",
       "      <td>10.670128</td>\n",
       "      <td>...</td>\n",
       "      <td>255.483337</td>\n",
       "      <td>3.402269e-08</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.009983</td>\n",
       "      <td>1.033333</td>\n",
       "      <td>0.004797</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>476.230896</td>\n",
       "      <td>8.962503e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>UK</td>\n",
       "      <td>B00AH02IWG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.388571</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.194766</td>\n",
       "      <td>2.851667e-04</td>\n",
       "      <td>11.166204</td>\n",
       "      <td>...</td>\n",
       "      <td>255.024780</td>\n",
       "      <td>2.150898e-08</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.006656</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>0.005803</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>472.108978</td>\n",
       "      <td>1.453126e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>UK</td>\n",
       "      <td>B00I0UKKD4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.388571</td>\n",
       "      <td>17.049999</td>\n",
       "      <td>118.0</td>\n",
       "      <td>11.835367</td>\n",
       "      <td>1.990737e-04</td>\n",
       "      <td>11.681271</td>\n",
       "      <td>...</td>\n",
       "      <td>267.615601</td>\n",
       "      <td>6.320386e-03</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.004992</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>0.008512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>482.222168</td>\n",
       "      <td>3.584311e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77570148</th>\n",
       "      <td>361580</td>\n",
       "      <td>DE</td>\n",
       "      <td>B0BB7XV97M</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.424000</td>\n",
       "      <td>47.990002</td>\n",
       "      <td>56.0</td>\n",
       "      <td>9.117821</td>\n",
       "      <td>6.076918e-05</td>\n",
       "      <td>9.635838</td>\n",
       "      <td>...</td>\n",
       "      <td>263.574158</td>\n",
       "      <td>1.367507e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>388.997711</td>\n",
       "      <td>1.905752e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77570149</th>\n",
       "      <td>361580</td>\n",
       "      <td>DE</td>\n",
       "      <td>B0BB7YSRBX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.424000</td>\n",
       "      <td>43.990002</td>\n",
       "      <td>58.0</td>\n",
       "      <td>9.163816</td>\n",
       "      <td>6.362959e-05</td>\n",
       "      <td>9.159988</td>\n",
       "      <td>...</td>\n",
       "      <td>263.523743</td>\n",
       "      <td>1.300273e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>388.911377</td>\n",
       "      <td>1.748122e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77570150</th>\n",
       "      <td>361580</td>\n",
       "      <td>DE</td>\n",
       "      <td>B0BB7ZMGY8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.424000</td>\n",
       "      <td>41.990002</td>\n",
       "      <td>452.0</td>\n",
       "      <td>11.256460</td>\n",
       "      <td>5.158017e-04</td>\n",
       "      <td>10.119755</td>\n",
       "      <td>...</td>\n",
       "      <td>263.567017</td>\n",
       "      <td>1.357776e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>387.696472</td>\n",
       "      <td>5.187348e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77570151</th>\n",
       "      <td>361580</td>\n",
       "      <td>DE</td>\n",
       "      <td>B0BD4CP7N3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.424000</td>\n",
       "      <td>24.990000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.778687</td>\n",
       "      <td>1.523355e-10</td>\n",
       "      <td>-1.612869</td>\n",
       "      <td>...</td>\n",
       "      <td>265.401611</td>\n",
       "      <td>8.503204e-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>384.966888</td>\n",
       "      <td>3.384560e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77570152</th>\n",
       "      <td>361580</td>\n",
       "      <td>DE</td>\n",
       "      <td>B0BL17QFL2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.424000</td>\n",
       "      <td>67.989998</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.492291</td>\n",
       "      <td>8.058466e-08</td>\n",
       "      <td>4.621465</td>\n",
       "      <td>...</td>\n",
       "      <td>256.451294</td>\n",
       "      <td>1.102831e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>386.365875</td>\n",
       "      <td>1.371117e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77570153 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sess_id sess_locale     product  target  sess_avg_price  \\\n",
       "0               0          UK  B000V599Y2     0.0        7.388571   \n",
       "1               0          UK  B007VZUA7U     0.0        7.388571   \n",
       "2               0          UK  B009EUAEQC     0.0        7.388571   \n",
       "3               0          UK  B00AH02IWG     0.0        7.388571   \n",
       "4               0          UK  B00I0UKKD4     0.0        7.388571   \n",
       "...           ...         ...         ...     ...             ...   \n",
       "77570148   361580          DE  B0BB7XV97M     0.0       32.424000   \n",
       "77570149   361580          DE  B0BB7YSRBX     0.0       32.424000   \n",
       "77570150   361580          DE  B0BB7ZMGY8     0.0       32.424000   \n",
       "77570151   361580          DE  B0BD4CP7N3     0.0       32.424000   \n",
       "77570152   361580          DE  B0BL17QFL2     0.0       32.424000   \n",
       "\n",
       "          product_price  product_freq  sasrec_scores_2  \\\n",
       "0              5.200000          37.0        13.152878   \n",
       "1              7.000000          36.0         9.393598   \n",
       "2              7.490000           4.0        11.754339   \n",
       "3              8.500000           3.0        12.194766   \n",
       "4             17.049999         118.0        11.835367   \n",
       "...                 ...           ...              ...   \n",
       "77570148      47.990002          56.0         9.117821   \n",
       "77570149      43.990002          58.0         9.163816   \n",
       "77570150      41.990002         452.0        11.256460   \n",
       "77570151      24.990000           1.0        -3.778687   \n",
       "77570152      67.989998           6.0         2.492291   \n",
       "\n",
       "          normalized_sasrec_scores_2  sasrec_scores_3  ...  roberta_scores  \\\n",
       "0                       7.433639e-04        10.677187  ...      259.157867   \n",
       "1                       1.732076e-05         8.838863  ...      257.981598   \n",
       "2                       1.835794e-04        10.670128  ...      255.483337   \n",
       "3                       2.851667e-04        11.166204  ...      255.024780   \n",
       "4                       1.990737e-04        11.681271  ...      267.615601   \n",
       "...                              ...              ...  ...             ...   \n",
       "77570148                6.076918e-05         9.635838  ...      263.574158   \n",
       "77570149                6.362959e-05         9.159988  ...      263.523743   \n",
       "77570150                5.158017e-04        10.119755  ...      263.567017   \n",
       "77570151                1.523355e-10        -1.612869  ...      265.401611   \n",
       "77570152                8.058466e-08         4.621465  ...      256.451294   \n",
       "\n",
       "          normalized_roberta_scores  co_graph_counts_0  \\\n",
       "0                      1.341519e-06                3.0   \n",
       "1                      4.137609e-07                3.0   \n",
       "2                      3.402269e-08                6.0   \n",
       "3                      2.150898e-08                4.0   \n",
       "4                      6.320386e-03                3.0   \n",
       "...                             ...                ...   \n",
       "77570148               1.367507e-03                0.0   \n",
       "77570149               1.300273e-03                0.0   \n",
       "77570150               1.357776e-03                0.0   \n",
       "77570151               8.503204e-03                0.0   \n",
       "77570152               1.102831e-06                0.0   \n",
       "\n",
       "          normalized_co_graph_counts_0  co_graph_counts_1  \\\n",
       "0                             0.004992           0.000000   \n",
       "1                             0.004992           0.000000   \n",
       "2                             0.009983           1.033333   \n",
       "3                             0.006656           1.250000   \n",
       "4                             0.004992           1.833333   \n",
       "...                                ...                ...   \n",
       "77570148                      0.000000           0.000000   \n",
       "77570149                      0.000000           0.000000   \n",
       "77570150                      0.000000           0.000000   \n",
       "77570151                      0.000000           0.000000   \n",
       "77570152                      0.000000           0.000000   \n",
       "\n",
       "          normalized_co_graph_counts_1  co_graph_counts_2  \\\n",
       "0                             0.000000                0.0   \n",
       "1                             0.000000                0.0   \n",
       "2                             0.004797                0.0   \n",
       "3                             0.005803                1.0   \n",
       "4                             0.008512                1.0   \n",
       "...                                ...                ...   \n",
       "77570148                      0.000000                0.0   \n",
       "77570149                      0.000000                0.0   \n",
       "77570150                      0.000000                0.0   \n",
       "77570151                      0.000000                0.0   \n",
       "77570152                      0.000000                0.0   \n",
       "\n",
       "          normalized_co_graph_counts_2  bert_scores  normalized_bert_scores  \n",
       "0                             0.000000   476.148773            8.255889e-06  \n",
       "1                             0.000000   475.083313            2.844725e-06  \n",
       "2                             0.000000   476.230896            8.962503e-06  \n",
       "3                             0.007937   472.108978            1.453126e-07  \n",
       "4                             0.007937   482.222168            3.584311e-03  \n",
       "...                                ...          ...                     ...  \n",
       "77570148                      0.000000   388.997711            1.905752e-04  \n",
       "77570149                      0.000000   388.911377            1.748122e-04  \n",
       "77570150                      0.000000   387.696472            5.187348e-05  \n",
       "77570151                      0.000000   384.966888            3.384560e-06  \n",
       "77570152                      0.000000   386.365875            1.371117e-05  \n",
       "\n",
       "[77570153 rows x 39 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_candidates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
