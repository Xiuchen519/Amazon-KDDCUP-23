{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cudf, itertools\n",
    "import scipy.sparse as ssp\n",
    "from functools import lru_cache\n",
    "from tqdm import tqdm, trange\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import xgboost as xgb \n",
    "from sklearn.model_selection import GroupKFold\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_candidates_path = '/root/autodl-tmp/xiaolong/WorkSpace/Amazon-KDDCUP-23/XGBoost/candidates/merged_candidates_feature.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=1)\n",
    "def read_merged_candidates():\n",
    "    return pd.read_parquet(merged_candidates_path, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_with_features = read_merged_candidates()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sess_id</th>\n",
       "      <th>sess_locale</th>\n",
       "      <th>product</th>\n",
       "      <th>target</th>\n",
       "      <th>sasrec_normalized_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>UK</td>\n",
       "      <td>B06XG1LZ6Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.354775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>UK</td>\n",
       "      <td>B07C97X1VS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>UK</td>\n",
       "      <td>B01MYUDYP7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>UK</td>\n",
       "      <td>B09XQSP9LD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>UK</td>\n",
       "      <td>B09JRYQGY8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85657530</th>\n",
       "      <td>361580</td>\n",
       "      <td>DE</td>\n",
       "      <td>B0855LJWKZ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85657531</th>\n",
       "      <td>361580</td>\n",
       "      <td>DE</td>\n",
       "      <td>B097BSYMZF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85657532</th>\n",
       "      <td>361580</td>\n",
       "      <td>DE</td>\n",
       "      <td>B0797QKH2W</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85657533</th>\n",
       "      <td>361580</td>\n",
       "      <td>DE</td>\n",
       "      <td>B017BJD7QG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85657534</th>\n",
       "      <td>361580</td>\n",
       "      <td>DE</td>\n",
       "      <td>B00ZIWFV4U</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85657535 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sess_id sess_locale     product  target  sasrec_normalized_scores\n",
       "0               0          UK  B06XG1LZ6Z     1.0                  0.354775\n",
       "1               0          UK  B07C97X1VS     0.0                  0.000480\n",
       "2               0          UK  B01MYUDYP7     0.0                  0.029109\n",
       "3               0          UK  B09XQSP9LD     0.0                  0.001922\n",
       "4               0          UK  B09JRYQGY8     0.0                  0.000000\n",
       "...           ...         ...         ...     ...                       ...\n",
       "85657530   361580          DE  B0855LJWKZ     0.0                  0.000179\n",
       "85657531   361580          DE  B097BSYMZF     0.0                  0.000000\n",
       "85657532   361580          DE  B0797QKH2W     0.0                  0.000000\n",
       "85657533   361580          DE  B017BJD7QG     0.0                  0.000000\n",
       "85657534   361580          DE  B00ZIWFV4U     0.0                  0.000000\n",
       "\n",
       "[85657535 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_with_features_sasrec = candidates_with_features[['sess_id', 'sess_locale', 'product', 'target', 'sasrec_normalized_scores']].copy()\n",
    "candidates_with_features_sasrec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_with_features_sasrec.sort_values(by=['sess_id', 'sasrec_normalized_scores'], ascending=[True, False], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_with_features_sasrec.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_with_features_sasrec['n'] = candidates_with_features_sasrec.groupby('sess_id')['product'].cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_with_features_sasrec = candidates_with_features_sasrec[candidates_with_features_sasrec['n'] < 100]\n",
    "candidates_with_features_sasrec.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = candidates_with_features_sasrec[candidates_with_features_sasrec['target'] == 1.0]['n'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank = rank.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcg_100 = (1.0 / np.log2(rank + 1)).sum() / (candidates_with_features['sess_id'].max() + 1) * 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrr_100 = (1.0 / rank).sum() / (candidates_with_features['sess_id'].max() + 1) * 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3762735117535992, 0.30919878699608405)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_100, mrr_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "229240"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sess_id</th>\n",
       "      <th>sess_locale</th>\n",
       "      <th>product</th>\n",
       "      <th>target</th>\n",
       "      <th>sasrec_normalized_scores</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>UK</td>\n",
       "      <td>B06XGDZVZR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.388253</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>UK</td>\n",
       "      <td>B06XG1LZ6Z</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.354775</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>UK</td>\n",
       "      <td>B06XGD9VLV</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092891</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>UK</td>\n",
       "      <td>B01MYUDYP7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029109</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>UK</td>\n",
       "      <td>B076PN1SKG</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36158095</th>\n",
       "      <td>361580</td>\n",
       "      <td>DE</td>\n",
       "      <td>B0976C4GSV</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36158096</th>\n",
       "      <td>361580</td>\n",
       "      <td>DE</td>\n",
       "      <td>B07VC79R5G</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36158097</th>\n",
       "      <td>361580</td>\n",
       "      <td>DE</td>\n",
       "      <td>B01LW4PT7T</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36158098</th>\n",
       "      <td>361580</td>\n",
       "      <td>DE</td>\n",
       "      <td>B07GNVHQKQ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36158099</th>\n",
       "      <td>361580</td>\n",
       "      <td>DE</td>\n",
       "      <td>B09YD12Q45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36158100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sess_id sess_locale     product  target  sasrec_normalized_scores  \\\n",
       "0               0          UK  B06XGDZVZR     0.0                  0.388253   \n",
       "1               0          UK  B06XG1LZ6Z     1.0                  0.354775   \n",
       "2               0          UK  B06XGD9VLV     0.0                  0.092891   \n",
       "3               0          UK  B01MYUDYP7     0.0                  0.029109   \n",
       "4               0          UK  B076PN1SKG     0.0                  0.022821   \n",
       "...           ...         ...         ...     ...                       ...   \n",
       "36158095   361580          DE  B0976C4GSV     0.0                  0.000009   \n",
       "36158096   361580          DE  B07VC79R5G     0.0                  0.000009   \n",
       "36158097   361580          DE  B01LW4PT7T     0.0                  0.000008   \n",
       "36158098   361580          DE  B07GNVHQKQ     0.0                  0.000008   \n",
       "36158099   361580          DE  B09YD12Q45     0.0                  0.000008   \n",
       "\n",
       "           n  \n",
       "0          0  \n",
       "1          1  \n",
       "2          2  \n",
       "3          3  \n",
       "4          4  \n",
       "...       ..  \n",
       "36158095  95  \n",
       "36158096  96  \n",
       "36158097  97  \n",
       "36158098  98  \n",
       "36158099  99  \n",
       "\n",
       "[36158100 rows x 6 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_with_features_sasrec"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_with_features['target'] = candidates_with_features['target'].astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = set(candidates_with_features.columns)\n",
    "FEATURES.remove('sess_id'), FEATURES.remove('product'), FEATURES.remove('sess_locale'), FEATURES.remove('target')\n",
    "FEATURES = list(FEATURES)\n",
    "FOLDS = 5\n",
    "SEED = 42\n",
    "LR = 0.1\n",
    "\n",
    "# XGB MODEL PARAMETERS\n",
    "xgb_parms = { \n",
    "    'max_depth': 4, \n",
    "    'learning_rate': LR, \n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.5, \n",
    "    'eval_metric': 'ndcg@100-',\n",
    "    'objective': 'rank:ndcg',\n",
    "    # 'scale_pos_weight': 200,\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'predictor': 'gpu_predictor',\n",
    "    'random_state': SEED\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Fold 1\n",
      "### Train size 68526055 Valid size 17131480\n",
      "#########################\n",
      "[0]\ttrain-ndcg@100-:0.32564\tvalid-ndcg@100-:0.32508\n",
      "[100]\ttrain-ndcg@100-:0.39547\tvalid-ndcg@100-:0.39425\n",
      "[200]\ttrain-ndcg@100-:0.39744\tvalid-ndcg@100-:0.39599\n",
      "[300]\ttrain-ndcg@100-:0.39802\tvalid-ndcg@100-:0.39640\n",
      "[400]\ttrain-ndcg@100-:0.39818\tvalid-ndcg@100-:0.39650\n",
      "[500]\ttrain-ndcg@100-:0.39833\tvalid-ndcg@100-:0.39669\n",
      "[600]\ttrain-ndcg@100-:0.39849\tvalid-ndcg@100-:0.39675\n",
      "[700]\ttrain-ndcg@100-:0.39863\tvalid-ndcg@100-:0.39684\n",
      "[800]\ttrain-ndcg@100-:0.39866\tvalid-ndcg@100-:0.39686\n",
      "[900]\ttrain-ndcg@100-:0.39877\tvalid-ndcg@100-:0.39691\n",
      "[1000]\ttrain-ndcg@100-:0.39888\tvalid-ndcg@100-:0.39688\n",
      "[1100]\ttrain-ndcg@100-:0.39897\tvalid-ndcg@100-:0.39689\n",
      "[1200]\ttrain-ndcg@100-:0.39907\tvalid-ndcg@100-:0.39698\n",
      "[1300]\ttrain-ndcg@100-:0.39915\tvalid-ndcg@100-:0.39696\n",
      "[1400]\ttrain-ndcg@100-:0.39926\tvalid-ndcg@100-:0.39697\n",
      "[1500]\ttrain-ndcg@100-:0.39931\tvalid-ndcg@100-:0.39700\n",
      "[1600]\ttrain-ndcg@100-:0.39939\tvalid-ndcg@100-:0.39700\n",
      "[1627]\ttrain-ndcg@100-:0.39942\tvalid-ndcg@100-:0.39701\n",
      "Running time : 1093.61s\n",
      "#########################\n",
      "### Fold 2\n",
      "### Train size 68525917 Valid size 17131618\n",
      "#########################\n",
      "[0]\ttrain-ndcg@100-:0.32534\tvalid-ndcg@100-:0.32713\n",
      "[100]\ttrain-ndcg@100-:0.39495\tvalid-ndcg@100-:0.39642\n",
      "[200]\ttrain-ndcg@100-:0.39693\tvalid-ndcg@100-:0.39841\n",
      "[300]\ttrain-ndcg@100-:0.39748\tvalid-ndcg@100-:0.39885\n",
      "[400]\ttrain-ndcg@100-:0.39768\tvalid-ndcg@100-:0.39905\n",
      "[500]\ttrain-ndcg@100-:0.39781\tvalid-ndcg@100-:0.39905\n",
      "[600]\ttrain-ndcg@100-:0.39795\tvalid-ndcg@100-:0.39910\n",
      "[700]\ttrain-ndcg@100-:0.39807\tvalid-ndcg@100-:0.39915\n",
      "[800]\ttrain-ndcg@100-:0.39815\tvalid-ndcg@100-:0.39907\n",
      "[855]\ttrain-ndcg@100-:0.39819\tvalid-ndcg@100-:0.39915\n",
      "Running time : 327.26s\n",
      "#########################\n",
      "### Fold 3\n",
      "### Train size 68526056 Valid size 17131479\n",
      "#########################\n",
      "[0]\ttrain-ndcg@100-:0.32622\tvalid-ndcg@100-:0.32344\n",
      "[100]\ttrain-ndcg@100-:0.39579\tvalid-ndcg@100-:0.39304\n",
      "[200]\ttrain-ndcg@100-:0.39783\tvalid-ndcg@100-:0.39490\n",
      "[300]\ttrain-ndcg@100-:0.39839\tvalid-ndcg@100-:0.39537\n",
      "[400]\ttrain-ndcg@100-:0.39854\tvalid-ndcg@100-:0.39539\n",
      "[500]\ttrain-ndcg@100-:0.39867\tvalid-ndcg@100-:0.39551\n",
      "[600]\ttrain-ndcg@100-:0.39881\tvalid-ndcg@100-:0.39568\n",
      "[700]\ttrain-ndcg@100-:0.39891\tvalid-ndcg@100-:0.39568\n",
      "[800]\ttrain-ndcg@100-:0.39900\tvalid-ndcg@100-:0.39574\n",
      "[900]\ttrain-ndcg@100-:0.39914\tvalid-ndcg@100-:0.39578\n",
      "[1000]\ttrain-ndcg@100-:0.39923\tvalid-ndcg@100-:0.39585\n",
      "[1100]\ttrain-ndcg@100-:0.39934\tvalid-ndcg@100-:0.39583\n",
      "[1200]\ttrain-ndcg@100-:0.39938\tvalid-ndcg@100-:0.39589\n",
      "[1300]\ttrain-ndcg@100-:0.39946\tvalid-ndcg@100-:0.39585\n",
      "[1358]\ttrain-ndcg@100-:0.39952\tvalid-ndcg@100-:0.39582\n",
      "Running time : 471.95s\n",
      "#########################\n",
      "### Fold 4\n",
      "### Train size 68526056 Valid size 17131479\n",
      "#########################\n",
      "[0]\ttrain-ndcg@100-:0.32590\tvalid-ndcg@100-:0.32454\n",
      "[100]\ttrain-ndcg@100-:0.39565\tvalid-ndcg@100-:0.39392\n",
      "[200]\ttrain-ndcg@100-:0.39758\tvalid-ndcg@100-:0.39571\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "skf = GroupKFold(n_splits=FOLDS)\n",
    "cur_time = time.strftime(time.strftime(\"%Y_%m_%d_%H_%M_%S\",time.localtime()))\n",
    "for fold,(train_idx, valid_idx) in enumerate(skf.split(candidates_with_features, candidates_with_features['target'], groups=candidates_with_features['sess_id'] )):\n",
    "    \n",
    "    print('#'*25)\n",
    "    print('### Fold',fold+1)\n",
    "    print('### Train size',len(train_idx),'Valid size',len(valid_idx))\n",
    "    print('#'*25)\n",
    "\n",
    "    st_time = time.time()\n",
    "\n",
    "    X_train = candidates_with_features.loc[train_idx, FEATURES]\n",
    "    y_train = candidates_with_features.loc[train_idx, 'target']\n",
    "    sess_id_train = candidates_with_features.loc[train_idx, ['sess_id', 'target']]\n",
    "    group_size_train = sess_id_train.groupby(by='sess_id').count()['target'].to_numpy()\n",
    "\n",
    "    X_valid = candidates_with_features.loc[valid_idx, FEATURES]\n",
    "    y_valid = candidates_with_features.loc[valid_idx, 'target']\n",
    "\n",
    "    sess_id_valid = candidates_with_features.loc[valid_idx, ['sess_id', 'target']]\n",
    "    group_size_valid = sess_id_valid.groupby(by='sess_id').count()['target'].to_numpy()\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, y_train, group=group_size_train) \n",
    "    dvalid = xgb.DMatrix(X_valid, y_valid, group=group_size_valid) \n",
    "\n",
    "    res = {'train' : {'ndcg@100-' : []}, 'valid' : {'ndcg@100-' : []}}\n",
    "    model = xgb.train(xgb_parms, \n",
    "        dtrain=dtrain,\n",
    "        evals=[(dtrain,'train'),(dvalid,'valid')],\n",
    "        num_boost_round=10000,\n",
    "        early_stopping_rounds=200,\n",
    "        evals_result= res,\n",
    "        verbose_eval=100)\n",
    "    \n",
    "    ed_time = time.time()\n",
    "    \n",
    "    print(f'Running time : {(ed_time-st_time):.2f}s')\n",
    "\n",
    "    with open(f'./logs/XGB_{cur_time}.log', 'a') as f:\n",
    "        f.write(f'Fold {fold+1}\\n')\n",
    "        f.write(f'Train size {len(train_idx)} Valid size {len(valid_idx)}\\n')\n",
    "        f.write(f'Running time {(ed_time-st_time):.2f}s\\n')\n",
    "        f.write(f'Best score : {model.best_score} Best iteration : {model.best_iteration}')\n",
    "\n",
    "    model.save_model(f'./ckpt/XGB_fold{fold}.xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3965147149407589, 268)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score, model.best_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2023_04_27_15_48_11'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.38274415682679036,\n",
       " 0.38525110401614965,\n",
       " 0.3864662340732853,\n",
       " 0.3856892701242305,\n",
       " 0.3847776443043934,\n",
       " 0.38533471812624565,\n",
       " 0.38434389597064866,\n",
       " 0.3838187058267055,\n",
       " 0.3836032478157957,\n",
       " 0.383860969838811,\n",
       " 0.38428811920485106,\n",
       " 0.38551229849663504,\n",
       " 0.38553776543410123,\n",
       " 0.38656335141508025,\n",
       " 0.38709104003596845,\n",
       " 0.38714139945797704,\n",
       " 0.3875627586967175,\n",
       " 0.3884293929313646,\n",
       " 0.38817414351478147,\n",
       " 0.38805425244998143,\n",
       " 0.3877823724349577,\n",
       " 0.38767259635477747,\n",
       " 0.38758170136414066,\n",
       " 0.3873067159366182,\n",
       " 0.3880986438929723,\n",
       " 0.38884141423857066,\n",
       " 0.38935651750357986,\n",
       " 0.389324921524964,\n",
       " 0.38981563961057214,\n",
       " 0.3896386485636532,\n",
       " 0.38980044822079474,\n",
       " 0.39007727124743324,\n",
       " 0.3904067722967975,\n",
       " 0.3907997942181276,\n",
       " 0.3910714538401246,\n",
       " 0.3911392480480035,\n",
       " 0.3916225823765739,\n",
       " 0.3915699056550614,\n",
       " 0.3915298246535626,\n",
       " 0.3913974298491467,\n",
       " 0.39133137725701683,\n",
       " 0.39138908247713744,\n",
       " 0.3913098276311523,\n",
       " 0.39123924995070547,\n",
       " 0.3916864400482063,\n",
       " 0.3921442214594338,\n",
       " 0.3924122231509575,\n",
       " 0.39233553541025656,\n",
       " 0.39228723951057765,\n",
       " 0.3926255863020028,\n",
       " 0.3926162081830365,\n",
       " 0.39262557120611064,\n",
       " 0.392945628808395,\n",
       " 0.3931490982406707,\n",
       " 0.3931704893687309,\n",
       " 0.3931819586164335,\n",
       " 0.393135416483351,\n",
       " 0.3934572887064829,\n",
       " 0.39365440751442454,\n",
       " 0.3938107751013656,\n",
       " 0.39381413256750064,\n",
       " 0.3938481702294943,\n",
       " 0.3938306391126888,\n",
       " 0.3939554173782687,\n",
       " 0.3940836057069834,\n",
       " 0.39432765995846786,\n",
       " 0.3942928382100524,\n",
       " 0.39443142719138913,\n",
       " 0.39444180339720813,\n",
       " 0.39441671496415215,\n",
       " 0.3945632516762575,\n",
       " 0.39455073914212546,\n",
       " 0.3947081498201468,\n",
       " 0.3947080689803513,\n",
       " 0.39473052982754153,\n",
       " 0.3948575652808278,\n",
       " 0.39503364168070393,\n",
       " 0.3950621903757796,\n",
       " 0.3951504380371321,\n",
       " 0.39516326057565804,\n",
       " 0.39528233442889765,\n",
       " 0.3953608554985478,\n",
       " 0.3953633326575507,\n",
       " 0.3954927783709055,\n",
       " 0.3955155256299318,\n",
       " 0.39552961362741984,\n",
       " 0.3955669360354727,\n",
       " 0.39555966682857935,\n",
       " 0.3955645217625236,\n",
       " 0.3955894369826809,\n",
       " 0.39564172105973444,\n",
       " 0.3957508328767975,\n",
       " 0.3958224323532468,\n",
       " 0.39585520691742215,\n",
       " 0.39584480251926485,\n",
       " 0.39586970993172355,\n",
       " 0.39587064318705323,\n",
       " 0.39586394874743175,\n",
       " 0.39588611839369325,\n",
       " 0.39586770786585784,\n",
       " 0.39592337487473117,\n",
       " 0.3959392813518252,\n",
       " 0.3960564053106244,\n",
       " 0.3960660862602034,\n",
       " 0.3961182312424952,\n",
       " 0.3961356869448551,\n",
       " 0.3961582155125689,\n",
       " 0.3962102740688781,\n",
       " 0.3962453807881498,\n",
       " 0.3963098304476408,\n",
       " 0.3963706654800673,\n",
       " 0.3963808495656414,\n",
       " 0.39640864537536835,\n",
       " 0.3964459205327251,\n",
       " 0.39643335030124427,\n",
       " 0.3964631142172977,\n",
       " 0.3964615924451814,\n",
       " 0.39651403671809843,\n",
       " 0.39653263945044714,\n",
       " 0.3965540363215719,\n",
       " 0.39658623730270226,\n",
       " 0.39660445695312735,\n",
       " 0.39662061217942585,\n",
       " 0.3966447931502534,\n",
       " 0.396650947219103,\n",
       " 0.3966428081246038,\n",
       " 0.39669503626577785,\n",
       " 0.39669570961847544,\n",
       " 0.3966973551828025,\n",
       " 0.3967308611952117,\n",
       " 0.3967557190490026,\n",
       " 0.3967447001095195,\n",
       " 0.3967757867652116,\n",
       " 0.39679197722934834,\n",
       " 0.3967949217017069,\n",
       " 0.3968329020996016,\n",
       " 0.396848251062735,\n",
       " 0.39686928607181765,\n",
       " 0.3969093773055533,\n",
       " 0.396931364658562,\n",
       " 0.3969245663798307,\n",
       " 0.39691448878316365,\n",
       " 0.39691166261862654,\n",
       " 0.39693140588856535,\n",
       " 0.3969704760246917,\n",
       " 0.3969969219658573,\n",
       " 0.39699577622996823,\n",
       " 0.3970130350824108,\n",
       " 0.39699890439454005,\n",
       " 0.39698987748915415,\n",
       " 0.39700306127996876,\n",
       " 0.39703296687232753,\n",
       " 0.3970652667982491,\n",
       " 0.3970576829713076,\n",
       " 0.39709295539110884,\n",
       " 0.39711083940215147,\n",
       " 0.3971257107676441,\n",
       " 0.3971143038971514,\n",
       " 0.39714212590242715,\n",
       " 0.3971657094900233,\n",
       " 0.3971962179675275,\n",
       " 0.3972368944328356,\n",
       " 0.39723651916158426,\n",
       " 0.397263786350951,\n",
       " 0.39726489654087643,\n",
       " 0.39724235950855674,\n",
       " 0.3972525661745645,\n",
       " 0.3972654097658217,\n",
       " 0.3972800190123501,\n",
       " 0.39729967866761706,\n",
       " 0.3973290317879724,\n",
       " 0.39735746180026377,\n",
       " 0.39735323892517255,\n",
       " 0.39735679263841117,\n",
       " 0.39737023631144613,\n",
       " 0.39739116047414386,\n",
       " 0.397390084081774,\n",
       " 0.39741270214219476,\n",
       " 0.3974123486857001,\n",
       " 0.3974060551189318,\n",
       " 0.39741584372264616,\n",
       " 0.39741537485755263,\n",
       " 0.3974117281180722,\n",
       " 0.39743033880441997,\n",
       " 0.39743371356851037,\n",
       " 0.39744947843216727,\n",
       " 0.3974598809406734,\n",
       " 0.3974467845871271,\n",
       " 0.39746226634202914,\n",
       " 0.39747016833347554,\n",
       " 0.3974801022111944,\n",
       " 0.3974692533122833,\n",
       " 0.39749656725312954,\n",
       " 0.39749765316967955,\n",
       " 0.39751607322327165,\n",
       " 0.3975351289656408,\n",
       " 0.39753899997067793,\n",
       " 0.3975634164132187,\n",
       " 0.3975683661457192,\n",
       " 0.3975675481394439,\n",
       " 0.39755909947079393,\n",
       " 0.39754593343668365,\n",
       " 0.39753719436332235,\n",
       " 0.39756727669074715,\n",
       " 0.39757363644242694,\n",
       " 0.3975950129044736,\n",
       " 0.39762242062443326,\n",
       " 0.3976237061785839,\n",
       " 0.3976209486099523,\n",
       " 0.3976256838853977,\n",
       " 0.397620275495066,\n",
       " 0.39762421577966617,\n",
       " 0.3976285016531288,\n",
       " 0.39763689375460615,\n",
       " 0.39767117027992627,\n",
       " 0.3976735441016253,\n",
       " 0.397679137402617,\n",
       " 0.3976824123061135,\n",
       " 0.39768625205163327,\n",
       " 0.3976933757451724,\n",
       " 0.3976876692136413,\n",
       " 0.3976804808498692,\n",
       " 0.39768150532287305,\n",
       " 0.3976736879454504,\n",
       " 0.3976739466857036,\n",
       " 0.39769027446249233,\n",
       " 0.3976966300193528,\n",
       " 0.39770616428796624,\n",
       " 0.3977202828148743,\n",
       " 0.39771767269894365,\n",
       " 0.39773221189354,\n",
       " 0.39773367395338677,\n",
       " 0.39773965173476705,\n",
       " 0.39775863731628996,\n",
       " 0.39775879531419234,\n",
       " 0.3977717591379874,\n",
       " 0.39776250645708977,\n",
       " 0.3977744814158246,\n",
       " 0.3977755852261633,\n",
       " 0.39776566783783973,\n",
       " 0.3977694742601136,\n",
       " 0.39778487255030176,\n",
       " 0.3977812652547973,\n",
       " 0.3977879264404512,\n",
       " 0.39779222934362307,\n",
       " 0.39779274775273,\n",
       " 0.3978089093212031,\n",
       " 0.39781546333206275,\n",
       " 0.3978263232797995,\n",
       " 0.3978309155849105,\n",
       " 0.39782780608127727,\n",
       " 0.39783495898330484,\n",
       " 0.39783212709679194,\n",
       " 0.3978441814362357,\n",
       " 0.39783906683029224,\n",
       " 0.39783320336472067,\n",
       " 0.3978434049943764,\n",
       " 0.39785057626263376,\n",
       " 0.39786678752385746,\n",
       " 0.3978605569563575,\n",
       " 0.3978575451516097,\n",
       " 0.3978623283516167,\n",
       " 0.397873089147299,\n",
       " 0.39786511227138893,\n",
       " 0.39788024128890565,\n",
       " 0.3978732795687387,\n",
       " 0.3978729360036443,\n",
       " 0.39786966595218654,\n",
       " 0.39787381840977537,\n",
       " 0.39787723377669776,\n",
       " 0.3978878335480883,\n",
       " 0.3978822380291274,\n",
       " 0.39788091961839045,\n",
       " 0.3978877087353139,\n",
       " 0.39789028104931995,\n",
       " 0.3978976199874302,\n",
       " 0.3978994753383026,\n",
       " 0.3979073393198582,\n",
       " 0.39791413820406224,\n",
       " 0.3979218963614041,\n",
       " 0.39791164327032075,\n",
       " 0.3979183825271897,\n",
       " 0.3979145932666849,\n",
       " 0.3979121660165169,\n",
       " 0.3979259595369295,\n",
       " 0.3979502069405917,\n",
       " 0.39794871239082097,\n",
       " 0.39795011553722,\n",
       " 0.3979551381205213,\n",
       " 0.3979556372222525,\n",
       " 0.3979690580850918,\n",
       " 0.39796560520281893,\n",
       " 0.3979698438055578,\n",
       " 0.39797164510067295,\n",
       " 0.39798611945966034,\n",
       " 0.39798930917662095,\n",
       " 0.39798370666640204,\n",
       " 0.39798917185244764,\n",
       " 0.3979942297361654,\n",
       " 0.39800565293837176]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['train']['ndcg@100-']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
